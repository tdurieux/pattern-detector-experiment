diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
index a0b98396..c4add7c3 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
@@ -32,6 +32,7 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Arabic. 
@@ -69,10 +70,22 @@
    */
   public static final String STOPWORDS_COMMENT = "#";
 
+  private final Version matchVersion;
+
   /**
    * Builds an analyzer with the default stop words: {@link #DEFAULT_STOPWORD_FILE}.
+   *
+   * @deprecated Use {@link #ArabicAnalyzer(Version)} instead
    */
   public ArabicAnalyzer() {
+    this(Version.LUCENE_24);
+  }
+
+  /**
+   * Builds an analyzer with the default stop words: {@link #DEFAULT_STOPWORD_FILE}.
+   */
+  public ArabicAnalyzer(Version matchVersion) {
+    this.matchVersion = matchVersion;
     try {
       InputStream stream = ArabicAnalyzer.class.getResourceAsStream(DEFAULT_STOPWORD_FILE);
       InputStreamReader reader = new InputStreamReader(stream, "UTF-8");
@@ -87,23 +100,53 @@ public ArabicAnalyzer() {
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #ArabicAnalyzer(Version, String[])} instead
    */
   public ArabicAnalyzer( String[] stopwords ) {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public ArabicAnalyzer( Version matchVersion, String[] stopwords ) {
     stoptable = StopFilter.makeStopSet( stopwords );
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #ArabicAnalyzer(Version, Hashtable)} instead
    */
   public ArabicAnalyzer( Hashtable stopwords ) {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public ArabicAnalyzer( Version matchVersion, Hashtable stopwords ) {
     stoptable = new HashSet(stopwords.keySet());
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.  Lines can be commented out using {@link #STOPWORDS_COMMENT}
+   *
+   * @deprecated Use {@link #ArabicAnalyzer(Version, File)} instead
    */
   public ArabicAnalyzer( File stopwords ) throws IOException {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.  Lines can be commented out using {@link #STOPWORDS_COMMENT}
+   */
+  public ArabicAnalyzer( Version matchVersion, File stopwords ) throws IOException {
     stoptable = WordlistLoader.getWordSet( stopwords, STOPWORDS_COMMENT);
+    this.matchVersion = matchVersion;
   }
 
 
@@ -117,7 +160,8 @@ public ArabicAnalyzer( File stopwords ) throws IOException {
   public final TokenStream tokenStream(String fieldName, Reader reader) {
     TokenStream result = new ArabicLetterTokenizer( reader );
     result = new LowerCaseFilter(result);
-    result = new StopFilter( result, stoptable );
+    result = new StopFilter( StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                             result, stoptable );
     result = new ArabicNormalizationFilter( result );
     result = new ArabicStemFilter( result );
 
@@ -144,7 +188,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       streams = new SavedStreams();
       streams.source = new ArabicLetterTokenizer(reader);
       streams.result = new LowerCaseFilter(streams.source);
-      streams.result = new StopFilter(streams.result, stoptable);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stoptable);
       streams.result = new ArabicNormalizationFilter(streams.result);
       streams.result = new ArabicStemFilter(streams.result);
       setPreviousTokenStream(streams);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
index f0efada4..b75ea1fe 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
@@ -32,6 +32,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Brazilian Portuguese language. 
@@ -40,6 +41,9 @@
  * will not be indexed at all) and an external list of exclusions (words that will
  * not be stemmed, but indexed).
  * </p>
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public final class BrazilianAnalyzer extends Analyzer {
 
@@ -77,33 +81,73 @@
 	 * Contains words that should be indexed but not stemmed.
 	 */
 	private Set excltable = new HashSet();
+        private final Version matchVersion;
 
 	/**
 	 * Builds an analyzer with the default stop words ({@link #BRAZILIAN_STOP_WORDS}).
+         *
+         * @deprecated Use {@link #BrazilianAnalyzer(Version)} instead
 	 */
 	public BrazilianAnalyzer() {
+          this(Version.LUCENE_23);
+	}
+
+	/**
+	 * Builds an analyzer with the default stop words ({@link #BRAZILIAN_STOP_WORDS}).
+	 */
+	public BrazilianAnalyzer(Version matchVersion) {
 		stoptable = StopFilter.makeStopSet( BRAZILIAN_STOP_WORDS );
+          this.matchVersion = matchVersion;
 	}
 
 	/**
 	 * Builds an analyzer with the given stop words.
+         * 
+         * @deprecated Use {@link #BrazilianAnalyzer(Version, String[])} instead
 	 */
 	public BrazilianAnalyzer( String[] stopwords ) {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+        public BrazilianAnalyzer( Version matchVersion, String[] stopwords ) {
 		stoptable = StopFilter.makeStopSet( stopwords );
+          this.matchVersion = matchVersion;
 	}
 
 	/**
 	 * Builds an analyzer with the given stop words.
+         *
+         * @deprecated Use {@link #BrazilianAnalyzer(Version, Map)} instead
 	 */
 	public BrazilianAnalyzer( Map stopwords ) {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+        public BrazilianAnalyzer( Version matchVersion, Map stopwords ) {
 		stoptable = new HashSet(stopwords.keySet());
+          this.matchVersion = matchVersion;
 	}
 
 	/**
 	 * Builds an analyzer with the given stop words.
+         * @deprecated Use {@link #BrazilianAnalyzer(Version, File)} instead
 	 */
 	public BrazilianAnalyzer( File stopwords ) throws IOException {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+        public BrazilianAnalyzer( Version matchVersion, File stopwords ) throws IOException {
 		stoptable = WordlistLoader.getWordSet( stopwords );
+          this.matchVersion = matchVersion;
 	}
 
 	/**
@@ -136,10 +180,11 @@ public void setStemExclusionTable( File exclusionlist ) throws IOException {
 	 *          {@link BrazilianStemFilter}.
 	 */
 	public final TokenStream tokenStream(String fieldName, Reader reader) {
-		TokenStream result = new StandardTokenizer( reader );
+                TokenStream result = new StandardTokenizer( matchVersion, reader );
 		result = new LowerCaseFilter( result );
 		result = new StandardFilter( result );
-		result = new StopFilter( result, stoptable );
+		result = new StopFilter( StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                         result, stoptable );
 		result = new BrazilianStemFilter( result, excltable );
 		return result;
 	}
@@ -162,10 +207,11 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       SavedStreams streams = (SavedStreams) getPreviousTokenStream();
       if (streams == null) {
         streams = new SavedStreams();
-        streams.source = new StandardTokenizer(reader);
+        streams.source = new StandardTokenizer(matchVersion, reader);
         streams.result = new LowerCaseFilter(streams.source);
         streams.result = new StandardFilter(streams.result);
-        streams.result = new StopFilter(streams.result, stoptable);
+        streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                        streams.result, stoptable);
         streams.result = new BrazilianStemFilter(streams.result, excltable);
         setPreviousTokenStream(streams);
       } else {
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
index f5e871b5..5f012536 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
@@ -21,6 +21,7 @@
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -56,23 +57,45 @@
    * stop word list
    */
   private Set stopTable;
+  private final Version matchVersion;
 
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Builds an analyzer which removes words in {@link #STOP_WORDS}.
+   *
+   * @deprecated Use {@link #CJKAnalyzer(Version)} instead
    */
   public CJKAnalyzer() {
+    this(Version.LUCENE_24);
+  }
+
+  /**
+   * Builds an analyzer which removes words in {@link #STOP_WORDS}.
+   */
+  public CJKAnalyzer(Version matchVersion) {
     stopTable = StopFilter.makeStopSet(STOP_WORDS);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer which removes words in the provided array.
    *
    * @param stopWords stop word array
+   * @deprecated Use {@link #CJKAnalyzer(Version, String[])} instead
    */
   public CJKAnalyzer(String[] stopWords) {
+    this(Version.LUCENE_24, stopWords);
+  }
+
+  /**
+   * Builds an analyzer which removes words in the provided array.
+   *
+   * @param stopWords stop word array
+   */
+  public CJKAnalyzer(Version matchVersion, String[] stopWords) {
     stopTable = StopFilter.makeStopSet(stopWords);
+    this.matchVersion = matchVersion;
   }
 
   //~ Methods ----------------------------------------------------------------
@@ -86,7 +109,8 @@ public CJKAnalyzer(String[] stopWords) {
    *    {@link StopFilter}
    */
   public final TokenStream tokenStream(String fieldName, Reader reader) {
-    return new StopFilter(new CJKTokenizer(reader), stopTable);
+    return new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                          new CJKTokenizer(reader), stopTable);
   }
   
   private class SavedStreams {
@@ -109,7 +133,8 @@ public final TokenStream reusableTokenStream(String fieldName, Reader reader) th
     if (streams == null) {
       streams = new SavedStreams();
       streams.source = new CJKTokenizer(reader);
-      streams.result = new StopFilter(streams.source, stopTable);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.source, stopTable);
       setPreviousTokenStream(streams);
     } else {
       streams.source.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
index 30b05345..cdbe4437 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -25,6 +25,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 import java.io.*;
 import java.util.HashSet;
@@ -37,6 +38,9 @@
  * will not be indexed at all). 
  * A default set of stopwords is used unless an alternative list is specified.
  * </p>
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public final class CzechAnalyzer extends Analyzer {
 
@@ -68,30 +72,68 @@
 	 * Contains the stopwords used with the {@link StopFilter}.
 	 */
 	private Set stoptable;
+        private final Version matchVersion;
 
 	/**
 	 * Builds an analyzer with the default stop words ({@link #CZECH_STOP_WORDS}).
+         *
+         * @deprecated Use {@link #CzechAnalyzer(Version)} instead
 	 */
 	public CzechAnalyzer() {
+          this(Version.LUCENE_23);
+	}
+	/**
+	 * Builds an analyzer with the default stop words ({@link #CZECH_STOP_WORDS}).
+	 */
+	public CzechAnalyzer(Version matchVersion) {
 		stoptable = StopFilter.makeStopSet( CZECH_STOP_WORDS );
+          this.matchVersion = matchVersion;
 	}
 
 	/**
 	 * Builds an analyzer with the given stop words.
+         *
+         * @deprecated Use {@link #CzechAnalyzer(Version, String[])} instead
 	 */
 	public CzechAnalyzer( String[] stopwords ) {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+        public CzechAnalyzer(Version matchVersion, String[] stopwords) {
 		stoptable = StopFilter.makeStopSet( stopwords );
+          this.matchVersion = matchVersion;
 	}
 
+        /**
+         * @deprecated Use {@link #CzechAnalyzer(Version, HashSet)} instead
+         */
 	public CzechAnalyzer( HashSet stopwords ) {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+        public CzechAnalyzer(Version matchVersion, HashSet stopwords) {
 		stoptable = stopwords;
+          this.matchVersion = matchVersion;
 	}
 
 	/**
 	 * Builds an analyzer with the given stop words.
+         *
+         * @deprecated Use {@link #CzechAnalyzer(Version, File)} instead
 	 */
 	public CzechAnalyzer( File stopwords ) throws IOException {
+          this(Version.LUCENE_23, stopwords);
+	}
+
+	/**
+	 * Builds an analyzer with the given stop words.
+	 */
+        public CzechAnalyzer(Version matchVersion, File stopwords ) throws IOException {
 		stoptable = WordlistLoader.getWordSet( stopwords );
+          this.matchVersion = matchVersion;
 	}
 
     /**
@@ -135,10 +177,11 @@ public void loadStopWords( InputStream wordfile, String encoding ) {
 	 * 			{@link StandardFilter}, {@link LowerCaseFilter}, and {@link StopFilter}
 	 */
 	public final TokenStream tokenStream( String fieldName, Reader reader ) {
-		TokenStream result = new StandardTokenizer( reader );
+                TokenStream result = new StandardTokenizer( matchVersion, reader );
 		result = new StandardFilter( result );
 		result = new LowerCaseFilter( result );
-		result = new StopFilter( result, stoptable );
+		result = new StopFilter( StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                         result, stoptable );
 		return result;
 	}
 	
@@ -159,10 +202,11 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       SavedStreams streams = (SavedStreams) getPreviousTokenStream();
       if (streams == null) {
         streams = new SavedStreams();
-        streams.source = new StandardTokenizer(reader);
+        streams.source = new StandardTokenizer(matchVersion, reader);
         streams.result = new StandardFilter(streams.source);
         streams.result = new LowerCaseFilter(streams.result);
-        streams.result = new StopFilter(streams.result, stoptable);
+        streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                        streams.result, stoptable);
         setPreviousTokenStream(streams);
       } else {
         streams.source.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
index d328ae82..387f97f9 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for German language. 
@@ -44,6 +45,9 @@
  * exclusion list is empty by default.
  * </p>
  * 
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
+ *
  * @version $Id$
  */
 public class GermanAnalyzer extends Analyzer {
@@ -76,37 +80,80 @@
    */
   private Set exclusionSet = new HashSet();
 
+  private final Version matchVersion;
+
   /**
    * Builds an analyzer with the default stop words:
    * {@link #GERMAN_STOP_WORDS}.
+   *
+   * @deprecated Use {@link #GermanAnalyzer(Version)} instead
    */
   public GermanAnalyzer() {
+    this(Version.LUCENE_23);
+  }
+
+  /**
+   * Builds an analyzer with the default stop words:
+   * {@link #GERMAN_STOP_WORDS}.
+   */
+  public GermanAnalyzer(Version matchVersion) {
     stopSet = StopFilter.makeStopSet(GERMAN_STOP_WORDS);
     setOverridesTokenStreamMethod(GermanAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #GermanAnalyzer(Version, String[])} instead
    */
   public GermanAnalyzer(String[] stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public GermanAnalyzer(Version matchVersion, String[] stopwords) {
     stopSet = StopFilter.makeStopSet(stopwords);
     setOverridesTokenStreamMethod(GermanAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #GermanAnalyzer(Version, Map)} instead
    */
   public GermanAnalyzer(Map stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public GermanAnalyzer(Version matchVersion, Map stopwords) {
     stopSet = new HashSet(stopwords.keySet());
     setOverridesTokenStreamMethod(GermanAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #GermanAnalyzer(Version, File)} instead
    */
   public GermanAnalyzer(File stopwords) throws IOException {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public GermanAnalyzer(Version matchVersion, File stopwords) throws IOException {
     stopSet = WordlistLoader.getWordSet(stopwords);
     setOverridesTokenStreamMethod(GermanAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
   /**
@@ -141,10 +188,11 @@ public void setStemExclusionTable(File exclusionlist) throws IOException {
    *         {@link GermanStemFilter}
    */
   public TokenStream tokenStream(String fieldName, Reader reader) {
-    TokenStream result = new StandardTokenizer(reader);
+    TokenStream result = new StandardTokenizer(matchVersion, reader);
     result = new StandardFilter(result);
     result = new LowerCaseFilter(result);
-    result = new StopFilter(result, stopSet);
+    result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                            result, stopSet);
     result = new GermanStemFilter(result, exclusionSet);
     return result;
   }
@@ -173,10 +221,11 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader) throws I
     SavedStreams streams = (SavedStreams) getPreviousTokenStream();
     if (streams == null) {
       streams = new SavedStreams();
-      streams.source = new StandardTokenizer(reader);
+      streams.source = new StandardTokenizer(matchVersion, reader);
       streams.result = new StandardFilter(streams.source);
       streams.result = new LowerCaseFilter(streams.result);
-      streams.result = new StopFilter(streams.result, stopSet);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stopSet);
       streams.result = new GermanStemFilter(streams.result, exclusionSet);
       setPreviousTokenStream(streams);
     } else {
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
index ddd90734..c6a44e1e 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
@@ -22,6 +22,7 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -36,6 +37,9 @@
  * that will not be indexed at all).
  * A default set of stopwords is used unless an alternative list is specified.
  * </p>
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public final class GreekAnalyzer extends Analyzer
 {
@@ -159,40 +163,62 @@
      */
     private char[] charset;
 
+    private final Version matchVersion;
+
+    /** @deprecated Use {@link #GreekAnalyzer(Version)} instead */
     public GreekAnalyzer() {
+      this(Version.LUCENE_23);
+    }
+
+    public GreekAnalyzer(Version matchVersion) {
         charset = GreekCharsets.UnicodeGreek;
         stopSet = StopFilter.makeStopSet(
                     makeStopWords(GreekCharsets.UnicodeGreek));
+        this.matchVersion = matchVersion;
     }
 
     /**
      * Builds an analyzer.
-     * @deprecated Use {@link #GreekAnalyzer()} instead.
+     * @deprecated Use {@link #GreekAnalyzer(Version)} instead.
      */
     public GreekAnalyzer(char[] charset)
     {
         this.charset = charset;
         stopSet = StopFilter.makeStopSet(makeStopWords(charset));
+        matchVersion = Version.LUCENE_23;
     }
     
     /**
      * Builds an analyzer with the given stop words.
      * @param stopwords Array of stopwords to use.
+     *
+     * @deprecated Use {@link #GreekAnalyzer(Version, String[])} instead
      */
     public GreekAnalyzer(String [] stopwords)
+    {
+      this(Version.LUCENE_23, stopwords);
+    }
+
+    /**
+     * Builds an analyzer with the given stop words.
+     * @param stopwords Array of stopwords to use.
+     */
+    public GreekAnalyzer(Version matchVersion, String [] stopwords)
     {
     	charset = GreekCharsets.UnicodeGreek;
     	stopSet = StopFilter.makeStopSet(stopwords);
+        this.matchVersion = matchVersion;
     }
 
     /**
      * Builds an analyzer with the given stop words.
-     * @deprecated Use {@link #GreekAnalyzer(String[])} instead.
+     * @deprecated Use {@link #GreekAnalyzer(Version, String[])} instead.
      */
     public GreekAnalyzer(char[] charset, String[] stopwords)
     {
         this.charset = charset;
         stopSet = StopFilter.makeStopSet(stopwords);
+        matchVersion = Version.LUCENE_23;
     }
 
     /**
@@ -219,21 +245,33 @@ public GreekAnalyzer(char[] charset, String[] stopwords)
 
     /**
      * Builds an analyzer with the given stop words.
-     * @deprecated Use {@link #GreekAnalyzer(Map)} instead.
+     * @deprecated Use {@link #GreekAnalyzer(Version, Map)} instead.
      */
     public GreekAnalyzer(char[] charset, Map stopwords)
     {
         this.charset = charset;
         stopSet = new HashSet(stopwords.keySet());
+        matchVersion = Version.LUCENE_23;
     }
     
     /**
      * Builds an analyzer with the given stop words.
+     *
+     * @deprecated Use {@link #GreekAnalyzer(Version,Map)} instead
      */
     public GreekAnalyzer(Map stopwords)
+    {
+      this(Version.LUCENE_23, stopwords);
+    }
+
+    /**
+     * Builds an analyzer with the given stop words.
+     */
+    public GreekAnalyzer(Version matchVersion, Map stopwords)
     {
     	charset = GreekCharsets.UnicodeGreek;
     	stopSet = new HashSet(stopwords.keySet());
+        this.matchVersion = matchVersion;
     }
 
     /**
@@ -244,9 +282,10 @@ public GreekAnalyzer(Map stopwords)
      */
     public TokenStream tokenStream(String fieldName, Reader reader)
     {
-    	TokenStream result = new StandardTokenizer(reader);
+        TokenStream result = new StandardTokenizer(matchVersion, reader);
         result = new GreekLowerCaseFilter(result, charset);
-        result = new StopFilter(result, stopSet);
+        result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                result, stopSet);
         return result;
     }
     
@@ -267,9 +306,10 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       SavedStreams streams = (SavedStreams) getPreviousTokenStream();
       if (streams == null) {
         streams = new SavedStreams();
-        streams.source = new StandardTokenizer(reader);
+        streams.source = new StandardTokenizer(matchVersion, reader);
         streams.result = new GreekLowerCaseFilter(streams.source, charset);
-        streams.result = new StopFilter(streams.result, stopSet);
+        streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                        streams.result, stopSet);
         setPreviousTokenStream(streams);
       } else {
         streams.source.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
index 65e463d3..9c2d09e5 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -34,6 +34,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.ar.ArabicLetterTokenizer;
 import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Persian.
@@ -66,11 +67,24 @@
    */
   public static final String STOPWORDS_COMMENT = "#";
 
+  private final Version matchVersion;
+
   /**
    * Builds an analyzer with the default stop words:
    * {@link #DEFAULT_STOPWORD_FILE}.
+   *
+   * @deprecated Use {@link #PersianAnalyzer(Version)} instead
    */
   public PersianAnalyzer() {
+    this(Version.LUCENE_24);
+  }
+
+  /**
+   * Builds an analyzer with the default stop words:
+   * {@link #DEFAULT_STOPWORD_FILE}.
+   */
+  public PersianAnalyzer(Version matchVersion) {
+    this.matchVersion = matchVersion;
     try {
       InputStream stream = PersianAnalyzer.class
           .getResourceAsStream(DEFAULT_STOPWORD_FILE);
@@ -86,24 +100,55 @@ public PersianAnalyzer() {
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #PersianAnalyzer(Version, String[])} instead
    */
   public PersianAnalyzer(String[] stopwords) {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public PersianAnalyzer(Version matchVersion, String[] stopwords) {
     stoptable = StopFilter.makeStopSet(stopwords);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #PersianAnalyzer(Version, Hashtable)} instead
    */
   public PersianAnalyzer(Hashtable stopwords) {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public PersianAnalyzer(Version matchVersion, Hashtable stopwords) {
     stoptable = new HashSet(stopwords.keySet());
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words. Lines can be commented out
    * using {@link #STOPWORDS_COMMENT}
+   *
+   * @deprecated Use {@link #PersianAnalyzer(Version, File)} instead
    */
   public PersianAnalyzer(File stopwords) throws IOException {
+    this(Version.LUCENE_24, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words. Lines can be commented out
+   * using {@link #STOPWORDS_COMMENT}
+   */
+  public PersianAnalyzer(Version matchVersion, File stopwords) throws IOException {
     stoptable = WordlistLoader.getWordSet(stopwords, STOPWORDS_COMMENT);
+    this.matchVersion = matchVersion;
   }
 
   /**
@@ -125,7 +170,8 @@ public TokenStream tokenStream(String fieldName, Reader reader) {
      * the order here is important: the stopword list is normalized with the
      * above!
      */
-    result = new StopFilter(result, stoptable);
+    result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                            result, stoptable);
 
     return result;
   }
@@ -158,7 +204,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
        * the order here is important: the stopword list is normalized with the
        * above!
        */
-      streams.result = new StopFilter(streams.result, stoptable);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stoptable);
       setPreviousTokenStream(streams);
     } else {
       streams.source.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
index bbcff01e..62de3c55 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
@@ -25,6 +25,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 import java.io.File;
 import java.io.IOException;
@@ -43,6 +44,17 @@
  * exclusion list is empty by default.
  * </p>
  *
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating FrenchAnalyzer:
+ * <ul>
+ *   <li> As of 2.9, StopFilter preserves position
+ *        increments
+ * </ul>
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
+ *
  * @version $Id$
  */
 public final class FrenchAnalyzer extends Analyzer {
@@ -84,26 +96,60 @@
    */
   private Set excltable = new HashSet();
 
+  private final Version matchVersion;
+
   /**
    * Builds an analyzer with the default stop words ({@link #FRENCH_STOP_WORDS}).
+   *
+   * @deprecated Use {@link #FrenchAnalyzer(Version)} instead.
    */
   public FrenchAnalyzer() {
+    this(Version.LUCENE_23);
+  }
+
+  /**
+   * Builds an analyzer with the default stop words ({@link #FRENCH_STOP_WORDS}).
+   */
+  public FrenchAnalyzer(Version matchVersion) {
     stoptable = StopFilter.makeStopSet(FRENCH_STOP_WORDS);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
+   *
+   * @deprecated Use {@link #FrenchAnalyzer(Version,
+   * String[])} instead.
    */
   public FrenchAnalyzer(String[] stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public FrenchAnalyzer(Version matchVersion, String[] stopwords) {
     stoptable = StopFilter.makeStopSet(stopwords);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
    * @throws IOException
+   *
+   * @deprecated Use {@link #FrenchAnalyzer(Version, File)} instead
    */
   public FrenchAnalyzer(File stopwords) throws IOException {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   * @throws IOException
+   */
+  public FrenchAnalyzer(Version matchVersion, File stopwords) throws IOException {
     stoptable = new HashSet(WordlistLoader.getWordSet(stopwords));
+    this.matchVersion = matchVersion;
   }
 
   /**
@@ -144,9 +190,10 @@ public final TokenStream tokenStream(String fieldName, Reader reader) {
     if (fieldName == null) throw new IllegalArgumentException("fieldName must not be null");
     if (reader == null) throw new IllegalArgumentException("reader must not be null");
 
-    TokenStream result = new StandardTokenizer(reader);
+    TokenStream result = new StandardTokenizer(matchVersion, reader);
     result = new StandardFilter(result);
-    result = new StopFilter(result, stoptable);
+    result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                            result, stoptable);
     result = new FrenchStemFilter(result, excltable);
     // Convert to lowercase after stemming!
     result = new LowerCaseFilter(result);
@@ -171,9 +218,10 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
     SavedStreams streams = (SavedStreams) getPreviousTokenStream();
     if (streams == null) {
       streams = new SavedStreams();
-      streams.source = new StandardTokenizer(reader);
+      streams.source = new StandardTokenizer(matchVersion, reader);
       streams.result = new StandardFilter(streams.source);
-      streams.result = new StopFilter(streams.result, stoptable);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stoptable);
       streams.result = new FrenchStemFilter(streams.result, excltable);
       // Convert to lowercase after stemming!
       streams.result = new LowerCaseFilter(streams.result);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
index ae40d4fe..72789404 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
@@ -23,6 +23,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 import java.io.File;
 import java.io.IOException;
@@ -42,6 +43,9 @@
  * A default set of stopwords is used unless an alternative list is specified, but the
  * exclusion list is empty by default.
  * </p>
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public class DutchAnalyzer extends Analyzer {
   /**
@@ -73,48 +77,92 @@
   private Set excltable = new HashSet();
 
   private Map stemdict = new HashMap();
-
+  private final Version matchVersion;
 
   /**
    * Builds an analyzer with the default stop words ({@link #DUTCH_STOP_WORDS}) 
    * and a few default entries for the stem exclusion table.
    * 
+   * @deprecated Use {@link #DutchAnalyzer(Version)} instead
    */
   public DutchAnalyzer() {
+    this(Version.LUCENE_23);
+  }
+
+  /**
+   * Builds an analyzer with the default stop words ({@link #DUTCH_STOP_WORDS}) 
+   * and a few default entries for the stem exclusion table.
+   * 
+   */
+  public DutchAnalyzer(Version matchVersion) {
     setOverridesTokenStreamMethod(DutchAnalyzer.class);
     stoptable = StopFilter.makeStopSet(DUTCH_STOP_WORDS);
     stemdict.put("fiets", "fiets"); //otherwise fiet
     stemdict.put("bromfiets", "bromfiets"); //otherwise bromfiet
     stemdict.put("ei", "eier");
     stemdict.put("kind", "kinder");
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
    *
    * @param stopwords
+   * @deprecated Use {@link #DutchAnalyzer(Version, String[])} instead
    */
   public DutchAnalyzer(String[] stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   *
+   * @param matchVersion
+   * @param stopwords
+   */
+  public DutchAnalyzer(Version matchVersion, String[] stopwords) {
     setOverridesTokenStreamMethod(DutchAnalyzer.class);
     stoptable = StopFilter.makeStopSet(stopwords);
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
    *
    * @param stopwords
+   * @deprecated Use {@link #DutchAnalyzer(Version, HashSet)} instead
    */
   public DutchAnalyzer(HashSet stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   *
+   * @param stopwords
+   */
+  public DutchAnalyzer(Version matchVersion, HashSet stopwords) {
     setOverridesTokenStreamMethod(DutchAnalyzer.class);
     stoptable = stopwords;
+    this.matchVersion = matchVersion;
   }
 
   /**
    * Builds an analyzer with the given stop words.
    *
    * @param stopwords
+   * @deprecated Use {@link #DutchAnalyzer(Version, File)} instead
    */
   public DutchAnalyzer(File stopwords) {
+    this(Version.LUCENE_23, stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   *
+   * @param stopwords
+   */
+  public DutchAnalyzer(Version matchVersion, File stopwords) {
     setOverridesTokenStreamMethod(DutchAnalyzer.class);
     try {
       stoptable = org.apache.lucene.analysis.WordlistLoader.getWordSet(stopwords);
@@ -122,6 +170,7 @@ public DutchAnalyzer(File stopwords) {
       // TODO: throw IOException
       throw new RuntimeException(e);
     }
+    this.matchVersion = matchVersion;
   }
 
   /**
@@ -179,9 +228,10 @@ public void setStemDictionary(File stemdictFile) {
    *   and {@link DutchStemFilter}
    */
   public TokenStream tokenStream(String fieldName, Reader reader) {
-    TokenStream result = new StandardTokenizer(reader);
+    TokenStream result = new StandardTokenizer(matchVersion, reader);
     result = new StandardFilter(result);
-    result = new StopFilter(result, stoptable);
+    result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                            result, stoptable);
     result = new DutchStemFilter(result, excltable, stemdict);
     return result;
   }
@@ -211,9 +261,10 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
     SavedStreams streams = (SavedStreams) getPreviousTokenStream();
     if (streams == null) {
       streams = new SavedStreams();
-      streams.source = new StandardTokenizer(reader);
+      streams.source = new StandardTokenizer(matchVersion, reader);
       streams.result = new StandardFilter(streams.source);
-      streams.result = new StopFilter(streams.result, stoptable);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stoptable);
       streams.result = new DutchStemFilter(streams.result, excltable, stemdict);
       setPreviousTokenStream(streams);
     } else {
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzer.java
index 2a284dee..12ddce68 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzer.java
@@ -23,6 +23,7 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.util.StringHelper;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -48,15 +49,27 @@
   //The default maximum percentage (40%) of index documents which
   //can contain a term, after which the term is considered to be a stop word.
   public static final float defaultMaxDocFreqPercent = 0.4f;
+  private final Version matchVersion;
 
   /**
    * Initializes this analyzer with the Analyzer object that actually produces the tokens
    *
    * @param delegate The choice of {@link Analyzer} that is used to produce the token stream which needs filtering
+   * @deprecated Use {@link #QueryAutoStopWordAnalyzer(Version, Analyzer)} instead
    */
   public QueryAutoStopWordAnalyzer(Analyzer delegate) {
+    this(Version.LUCENE_24, delegate);
+  }
+
+  /**
+   * Initializes this analyzer with the Analyzer object that actually produces the tokens
+   *
+   * @param delegate The choice of {@link Analyzer} that is used to produce the token stream which needs filtering
+   */
+  public QueryAutoStopWordAnalyzer(Version matchVersion, Analyzer delegate) {
     this.delegate = delegate;
     setOverridesTokenStreamMethod(QueryAutoStopWordAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
   /**
@@ -175,7 +188,8 @@ public TokenStream tokenStream(String fieldName, Reader reader) {
     }
     HashSet stopWords = (HashSet) stopWordsPerField.get(fieldName);
     if (stopWords != null) {
-      result = new StopFilter(result, stopWords);
+      result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                              result, stopWords);
     }
     return result;
   }
@@ -217,7 +231,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       /* if there are any stopwords for the field, save the stopfilter */
       HashSet stopWords = (HashSet) stopWordsPerField.get(fieldName);
       if (stopWords != null)
-        streams.withStopFilter = new StopFilter(streams.wrapped, stopWords);
+        streams.withStopFilter = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                                streams.wrapped, stopWords);
       else
         streams.withStopFilter = streams.wrapped;
 
@@ -238,7 +253,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
         streams.wrapped = result;
         HashSet stopWords = (HashSet) stopWordsPerField.get(fieldName);
         if (stopWords != null)
-          streams.withStopFilter = new StopFilter(streams.wrapped, stopWords);
+          streams.withStopFilter = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                                  streams.wrapped, stopWords);
         else
           streams.withStopFilter = streams.wrapped;
       }
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
index f423f75d..7ed264a3 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
@@ -27,6 +27,7 @@
 import org.apache.lucene.analysis.StopFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Russian language. 
@@ -193,41 +194,60 @@
      * @deprecated Support for non-Unicode encodings will be removed in Lucene 3.0
      */
     private char[] charset;
+    private final Version matchVersion;
 
-
+    /** @deprecated Use {@link #RussianAnalyzer(Version)} instead */
     public RussianAnalyzer() {
+      this(Version.LUCENE_24);
+    }
+
+    public RussianAnalyzer(Version matchVersion) {
         charset = RussianCharsets.UnicodeRussian;
         stopSet = StopFilter.makeStopSet(
                     makeStopWords(RussianCharsets.UnicodeRussian));
+        this.matchVersion = matchVersion;
     }
 
     /**
      * Builds an analyzer.
-     * @deprecated Use {@link #RussianAnalyzer()} instead.
+     * @deprecated Use {@link #RussianAnalyzer(Version)} instead.
      */
     public RussianAnalyzer(char[] charset)
     {
         this.charset = charset;
         stopSet = StopFilter.makeStopSet(makeStopWords(charset));
+        matchVersion = Version.LUCENE_24;
     }
 
     /**
      * Builds an analyzer with the given stop words.
-     * @deprecated Use {@link #RussianAnalyzer(String[])} instead.
+     * @deprecated Use {@link #RussianAnalyzer(Version,String[])} instead.
      */
     public RussianAnalyzer(char[] charset, String[] stopwords)
     {
         this.charset = charset;
         stopSet = StopFilter.makeStopSet(stopwords);
+        matchVersion = Version.LUCENE_24;
     }
     
     /**
      * Builds an analyzer with the given stop words.
+     *
+     * @deprecated Use {@link #RussianAnalyzer(Version,String[])} instead.
      */
     public RussianAnalyzer(String[] stopwords)
+    {
+      this(Version.LUCENE_24, stopwords);
+    }
+
+    /**
+     * Builds an analyzer with the given stop words.
+     */
+    public RussianAnalyzer(Version matchVersion, String[] stopwords)
     {
     	this.charset = RussianCharsets.UnicodeRussian;
     	stopSet = StopFilter.makeStopSet(stopwords);
+        this.matchVersion = matchVersion;
     }
 
     /** Takes russian stop words and translates them to a String array, using
@@ -254,22 +274,36 @@ public RussianAnalyzer(String[] stopwords)
     /**
      * Builds an analyzer with the given stop words.
      * TODO: create a Set version of this ctor
-     * @deprecated Use {@link #RussianAnalyzer(Map)} instead.
+     *
+     * @deprecated Use {@link #RussianAnalyzer(Version, Map)} instead.
      */
     public RussianAnalyzer(char[] charset, Map stopwords)
     {
         this.charset = charset;
         stopSet = new HashSet(stopwords.keySet());
+        matchVersion = Version.LUCENE_24;
     }
     
     /**
      * Builds an analyzer with the given stop words.
      * TODO: create a Set version of this ctor
+     *
+     * @deprecated Use {@link #RussianAnalyzer(Version, Map)} instead.
      */
     public RussianAnalyzer(Map stopwords)
+    {
+      this(Version.LUCENE_24, stopwords);
+    }
+
+    /**
+     * Builds an analyzer with the given stop words.
+     * TODO: create a Set version of this ctor
+     */
+    public RussianAnalyzer(Version matchVersion, Map stopwords)
     {
     	charset = RussianCharsets.UnicodeRussian;
     	stopSet = new HashSet(stopwords.keySet());
+        this.matchVersion = matchVersion;
     }
 
     /**
@@ -285,7 +319,8 @@ public TokenStream tokenStream(String fieldName, Reader reader)
     {
         TokenStream result = new RussianLetterTokenizer(reader, charset);
         result = new RussianLowerCaseFilter(result, charset);
-        result = new StopFilter(result, stopSet);
+        result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                result, stopSet);
         result = new RussianStemFilter(result, charset);
         return result;
     }
@@ -311,7 +346,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       streams = new SavedStreams();
       streams.source = new RussianLetterTokenizer(reader, charset);
       streams.result = new RussianLowerCaseFilter(streams.source, charset);
-      streams.result = new StopFilter(streams.result, stopSet);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, stopSet);
       streams.result = new RussianStemFilter(streams.result, charset);
       setPreviousTokenStream(streams);
     } else {
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
index a0d6ab44..fdf41094 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
@@ -25,22 +25,34 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Thai language. It uses {@link java.text.BreakIterator} to break words.
  * @version 0.2
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public class ThaiAnalyzer extends Analyzer {
+  private final Version matchVersion;
   
+  /** @deprecated Use {@link #ThaiAnalyzer(Version)} instead */
   public ThaiAnalyzer() {
+    this(Version.LUCENE_23);
+  }
+  
+  public ThaiAnalyzer(Version matchVersion) {
     setOverridesTokenStreamMethod(ThaiAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
   
   public TokenStream tokenStream(String fieldName, Reader reader) {
-	  TokenStream ts = new StandardTokenizer(reader);
+    TokenStream ts = new StandardTokenizer(matchVersion, reader);
     ts = new StandardFilter(ts);
     ts = new ThaiWordFilter(ts);
-    ts = new StopFilter(ts, StopAnalyzer.ENGLISH_STOP_WORDS_SET);
+    ts = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                        ts, StopAnalyzer.ENGLISH_STOP_WORDS_SET);
     return ts;
   }
   
@@ -60,10 +72,11 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader) throws I
     SavedStreams streams = (SavedStreams) getPreviousTokenStream();
     if (streams == null) {
       streams = new SavedStreams();
-      streams.source = new StandardTokenizer(reader);
+      streams.source = new StandardTokenizer(matchVersion, reader);
       streams.result = new StandardFilter(streams.source);
       streams.result = new ThaiWordFilter(streams.result);
-      streams.result = new StopFilter(streams.result, StopAnalyzer.ENGLISH_STOP_WORDS_SET);
+      streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                      streams.result, StopAnalyzer.ENGLISH_STOP_WORDS_SET);
       setPreviousTokenStream(streams);
     } else {
       streams.source.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
index c33ef7f1..9837b339 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
@@ -22,6 +22,7 @@
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.util.Version;
 
 /**
  * Test case for FrenchAnalyzer.
@@ -32,7 +33,7 @@
 public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 
 	public void testAnalyzer() throws Exception {
-		FrenchAnalyzer fa = new FrenchAnalyzer();
+		FrenchAnalyzer fa = new FrenchAnalyzer(Version.LUCENE_CURRENT);
 	
 		// test null reader
 		boolean iaeFlag = false;
diff --git a/lucene/java/branches/lucene_2_9/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
index 442c2651..b8bad506 100644
--- a/lucene/java/branches/lucene_2_9/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
@@ -31,6 +31,7 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.cn.smart.SentenceTokenizer;
 import org.apache.lucene.analysis.cn.smart.WordTokenFilter;
+import org.apache.lucene.util.Version;
 
 /**
  * <p>
@@ -59,12 +60,22 @@
 public class SmartChineseAnalyzer extends Analyzer {
 
   private final Set stopWords;
+  private final Version matchVersion;
 
   /**
    * Create a new SmartChineseAnalyzer, using the default stopword list.
+   *
+   * @deprecated Use {@link #SmartChineseAnalyzer(Version)} instead
    */
   public SmartChineseAnalyzer() {
-    this(true);
+    this(Version.LUCENE_24, true);
+  }
+
+  /**
+   * Create a new SmartChineseAnalyzer, using the default stopword list.
+   */
+  public SmartChineseAnalyzer(Version matchVersion) {
+    this(matchVersion, true);
   }
 
   /**
@@ -77,8 +88,26 @@ public SmartChineseAnalyzer() {
    * </p>
    * 
    * @param useDefaultStopWords true to use the default stopword list.
+   *
+   * @deprecated Use {@link #SmartChineseAnalyzer(Version, boolean)} instead
    */
   public SmartChineseAnalyzer(boolean useDefaultStopWords) {
+    this(Version.LUCENE_24, useDefaultStopWords);
+  }
+
+  /**
+   * <p>
+   * Create a new SmartChineseAnalyzer, optionally using the default stopword list.
+   * </p>
+   * <p>
+   * The included default stopword list is simply a list of punctuation.
+   * If you do not use this list, punctuation will not be removed from the text!
+   * </p>
+   * 
+   * @param useDefaultStopWords true to use the default stopword list.
+   */
+  public SmartChineseAnalyzer(Version matchVersion, boolean useDefaultStopWords) {
+    this.matchVersion = matchVersion;
     if (useDefaultStopWords) {
       try {
       InputStream stream = this.getClass().getResourceAsStream("stopwords.txt");
@@ -101,9 +130,25 @@ public SmartChineseAnalyzer(boolean useDefaultStopWords) {
    * Note: the set should include punctuation, unless you want to index punctuation!
    * </p>
    * @param stopWords {@link Set} of stopwords to use.
+   *
+   * @deprecated Use {@link #SmartChineseAnalyzer(Version, Set)} instead
    */
   public SmartChineseAnalyzer(Set stopWords) {
+    this(Version.LUCENE_24, stopWords);
+  }
+
+  /**
+   * <p>
+   * Create a new SmartChineseAnalyzer, using the provided {@link Set} of stopwords.
+   * </p>
+   * <p>
+   * Note: the set should include punctuation, unless you want to index punctuation!
+   * </p>
+   * @param stopWords {@link Set} of stopwords to use.
+   */
+  public SmartChineseAnalyzer(Version matchVersion, Set stopWords) {
     this.stopWords = stopWords;
+    this.matchVersion = matchVersion;
   }
 
   public TokenStream tokenStream(String fieldName, Reader reader) {
@@ -114,7 +159,8 @@ public TokenStream tokenStream(String fieldName, Reader reader) {
     // The porter stemming is too strict, this is not a bug, this is a feature:)
     result = new PorterStemFilter(result);
     if (stopWords != null) {
-      result = new StopFilter(result, stopWords, false);
+      result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                              result, stopWords, false);
     }
     return result;
   }
@@ -134,7 +180,8 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
       streams.filteredTokenStream = new WordTokenFilter(streams.tokenStream);
       streams.filteredTokenStream = new PorterStemFilter(streams.filteredTokenStream);
       if (stopWords != null) {
-        streams.filteredTokenStream = new StopFilter(streams.filteredTokenStream, stopWords, false);
+        streams.filteredTokenStream = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                                     streams.filteredTokenStream, stopWords, false);
       }
     } else {
       streams.tokenStream.reset(reader);
diff --git a/lucene/java/branches/lucene_2_9/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
index a88429fa..d389a681 100644
--- a/lucene/java/branches/lucene_2_9/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.lucene.util.Version;
 
 /**
  * Efficient Lucene analyzer/tokenizer that preferably operates on a String rather than a
@@ -140,6 +141,8 @@
   private final boolean toLowerCase;
   private final Set stopWords;
   
+  private final Version matchVersion;
+  
   /**
    * Constructs a new instance with the given parameters.
    * 
@@ -157,8 +160,33 @@
    *            <code>WordlistLoader.getWordSet(new File("samples/fulltext/stopwords.txt")</code>
    *            or <a href="http://www.unine.ch/info/clef/">other stop words
    *            lists </a>.
+   *
+   * @deprecated Use {@link #PatternAnalyzer(Version, Pattern, boolean, Set)} instead
    */
   public PatternAnalyzer(Pattern pattern, boolean toLowerCase, Set stopWords) {
+    this(Version.LUCENE_24, pattern, toLowerCase, stopWords);
+  }
+
+  /**
+   * Constructs a new instance with the given parameters.
+   * 
+   * @param matchVersion If >= {@link Version#LUCENE_29}, StopFilter.enablePositionIncrement is set to true
+   * @param pattern
+   *            a regular expression delimiting tokens
+   * @param toLowerCase
+   *            if <code>true</code> returns tokens after applying
+   *            String.toLowerCase()
+   * @param stopWords
+   *            if non-null, ignores all tokens that are contained in the
+   *            given stop set (after previously having applied toLowerCase()
+   *            if applicable). For example, created via
+   *            {@link StopFilter#makeStopSet(String[])}and/or
+   *            {@link org.apache.lucene.analysis.WordlistLoader}as in
+   *            <code>WordlistLoader.getWordSet(new File("samples/fulltext/stopwords.txt")</code>
+   *            or <a href="http://www.unine.ch/info/clef/">other stop words
+   *            lists </a>.
+   */
+  public PatternAnalyzer(Version matchVersion, Pattern pattern, boolean toLowerCase, Set stopWords) {
     if (pattern == null) 
       throw new IllegalArgumentException("pattern must not be null");
     
@@ -170,6 +198,7 @@ public PatternAnalyzer(Pattern pattern, boolean toLowerCase, Set stopWords) {
     this.pattern = pattern;
     this.toLowerCase = toLowerCase;
     this.stopWords = stopWords;
+    this.matchVersion = matchVersion;
   }
   
   /**
@@ -197,7 +226,7 @@ else if (pattern == WHITESPACE_PATTERN) { // fast path
     }
     else {
       stream = new PatternTokenizer(text, pattern, toLowerCase);
-      if (stopWords != null) stream = new StopFilter(false, stream, stopWords);
+      if (stopWords != null) stream = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion), stream, stopWords);
     }
     
     return stream;
diff --git a/lucene/java/branches/lucene_2_9/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java b/lucene/java/branches/lucene_2_9/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
index b304f8eb..1ade80c7 100644
--- a/lucene/java/branches/lucene_2_9/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
+++ b/lucene/java/branches/lucene_2_9/contrib/misc/src/java/org/apache/lucene/queryParser/complexPhrase/ComplexPhraseQueryParser.java
@@ -38,6 +38,7 @@
 import org.apache.lucene.search.spans.SpanOrQuery;
 import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.util.Version;
 
 /**
  * QueryParser which permits complex phrase query syntax eg "(john jon
@@ -67,8 +68,15 @@
 
   private ComplexPhraseQuery currentPhraseQuery = null;
 
+  /** @deprecated Use {@link
+  #ComplexPhraseQueryParser{Version, String, Analyzer)}
+  instead.*/
   public ComplexPhraseQueryParser(String f, Analyzer a) {
-    super(f, a);
+    this(Version.LUCENE_24, f, a);
+  }
+
+  public ComplexPhraseQueryParser(Version matchVersion, String f, Analyzer a) {
+    super(matchVersion, f, a);
   }
 
   protected Query getFieldQuery(String field, String queryText, int slop) {
diff --git a/lucene/java/branches/lucene_2_9/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java b/lucene/java/branches/lucene_2_9/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
index 882e77e7..fb0ace10 100644
--- a/lucene/java/branches/lucene_2_9/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
@@ -19,6 +19,7 @@
 
 import org.apache.lucene.analysis.*;
 import org.apache.lucene.analysis.standard.*;
+import org.apache.lucene.util.Version;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -30,20 +31,39 @@
  * Available stemmers are listed in org.tartarus.snowball.ext.  The name of a
  * stemmer is the part of the class name before "Stemmer", e.g., the stemmer in
  * {@link org.tartarus.snowball.ext.EnglishStemmer} is named "English".
+ *
+ * <p><b>NOTE</b>: This class uses the same {@link Version}
+ * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public class SnowballAnalyzer extends Analyzer {
   private String name;
   private Set stopSet;
+  private final Version matchVersion;
 
-  /** Builds the named analyzer with no stop words. */
+  /** Builds the named analyzer with no stop words.
+   *
+   * @deprecated Use {@link {#SnowballAnalyzer(Version, String)} instead*/
   public SnowballAnalyzer(String name) {
+    this(Version.LUCENE_23, name);
+  }
+
+  /** Builds the named analyzer with no stop words. */
+  public SnowballAnalyzer(Version matchVersion, String name) {
     this.name = name;
     setOverridesTokenStreamMethod(SnowballAnalyzer.class);
+    this.matchVersion = matchVersion;
   }
 
-  /** Builds the named analyzer with the given stop words. */
+  /** Builds the named analyzer with the given stop words.
+   *
+   * @deprecated Use {@link {#SnowballAnalyzer(Version, String, String[])} instead*/
   public SnowballAnalyzer(String name, String[] stopWords) {
-    this(name);
+    this(Version.LUCENE_23, name, stopWords);
+  }
+
+  /** Builds the named analyzer with the given stop words. */
+  public SnowballAnalyzer(Version matchVersion, String name, String[] stopWords) {
+    this(matchVersion, name);
     stopSet = StopFilter.makeStopSet(stopWords);
   }
 
@@ -51,11 +71,12 @@ public SnowballAnalyzer(String name, String[] stopWords) {
       StandardFilter}, a {@link LowerCaseFilter}, a {@link StopFilter},
       and a {@link SnowballFilter} */
   public TokenStream tokenStream(String fieldName, Reader reader) {
-    TokenStream result = new StandardTokenizer(reader);
+    TokenStream result = new StandardTokenizer(matchVersion, reader);
     result = new StandardFilter(result);
     result = new LowerCaseFilter(result);
     if (stopSet != null)
-      result = new StopFilter(result, stopSet);
+      result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                              result, stopSet);
     result = new SnowballFilter(result, name);
     return result;
   }
@@ -80,11 +101,12 @@ public TokenStream reusableTokenStream(String fieldName, Reader reader)
     SavedStreams streams = (SavedStreams) getPreviousTokenStream();
     if (streams == null) {
       streams = new SavedStreams();
-      streams.source = new StandardTokenizer(reader);
+      streams.source = new StandardTokenizer(matchVersion, reader);
       streams.result = new StandardFilter(streams.source);
       streams.result = new LowerCaseFilter(streams.result);
       if (stopSet != null)
-        streams.result = new StopFilter(streams.result, stopSet);
+        streams.result = new StopFilter(StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion),
+                                        streams.result, stopSet);
       streams.result = new SnowballFilter(streams.result, name);
       setPreviousTokenStream(streams);
     } else {
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopAnalyzer.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopAnalyzer.java
index 42a84f2a..272365c1 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopAnalyzer.java
@@ -23,7 +23,18 @@
 import java.util.Arrays;
 import java.util.Set;
 
-/** Filters {@link LetterTokenizer} with {@link LowerCaseFilter} and {@link StopFilter}. */
+import org.apache.lucene.util.Version;
+
+/** Filters {@link LetterTokenizer} with {@link
+ * LowerCaseFilter} and {@link StopFilter}.
+ *
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating StopAnalyzer:
+ * <ul>
+ *   <li> As of 2.9, position increments are preserved
+ * </ul>
+*/
 
 public final class StopAnalyzer extends Analyzer {
   private final Set/*<String>*/ stopWords;
@@ -61,17 +72,26 @@
   
   /** Builds an analyzer which removes words in
    * ENGLISH_STOP_WORDS.
-   * @deprecated Use {@link #StopAnalyzer(boolean)} instead */
+   * @deprecated Use {@link #StopAnalyzer(Version)} instead */
   public StopAnalyzer() {
     stopWords = ENGLISH_STOP_WORDS_SET;
     useDefaultStopPositionIncrement = true;
     enablePositionIncrements = false;
   }
 
+  /** Builds an analyzer which removes words in
+   * ENGLISH_STOP_WORDS.*/
+  public StopAnalyzer(Version matchVersion) {
+    stopWords = ENGLISH_STOP_WORDS_SET;
+    useDefaultStopPositionIncrement = false;
+    enablePositionIncrements = StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion);
+  }
+
   /** Builds an analyzer which removes words in
    *  ENGLISH_STOP_WORDS.
    * @param enablePositionIncrements See {@link
-   * StopFilter#setEnablePositionIncrements} */
+   * StopFilter#setEnablePositionIncrements} 
+   * @deprecated Use {@link #StopAnalyzer(Version)} instead */
   public StopAnalyzer(boolean enablePositionIncrements) {
     stopWords = ENGLISH_STOP_WORDS_SET;
     this.enablePositionIncrements = enablePositionIncrements;
@@ -79,17 +99,26 @@ public StopAnalyzer(boolean enablePositionIncrements) {
   }
 
   /** Builds an analyzer with the stop words from the given set.
-   * @deprecated Use {@link #StopAnalyzer(Set, boolean)} instead */
+   * @deprecated Use {@link #StopAnalyzer(Version, Set)} instead */
   public StopAnalyzer(Set stopWords) {
     this.stopWords = stopWords;
     useDefaultStopPositionIncrement = true;
     enablePositionIncrements = false;
   }
 
+  /** Builds an analyzer with the stop words from the given
+   * set. */
+  public StopAnalyzer(Version matchVersion, Set stopWords) {
+    this.stopWords = stopWords;
+    useDefaultStopPositionIncrement = false;
+    enablePositionIncrements = StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion);
+  }
+
   /** Builds an analyzer with the stop words from the given set.
    * @param stopWords Set of stop words
    * @param enablePositionIncrements See {@link
-   * StopFilter#setEnablePositionIncrements} */
+   * StopFilter#setEnablePositionIncrements}
+   * @deprecated Use {@link #StopAnalyzer(Version, Set)} instead */
   public StopAnalyzer(Set stopWords, boolean enablePositionIncrements) {
     this.stopWords = stopWords;
     this.enablePositionIncrements = enablePositionIncrements;
@@ -97,7 +126,7 @@ public StopAnalyzer(Set stopWords, boolean enablePositionIncrements) {
   }
 
   /** Builds an analyzer which removes words in the provided array.
-   * @deprecated Use {@link #StopAnalyzer(Set, boolean)} instead */
+   * @deprecated Use {@link #StopAnalyzer(Version, Set)} instead */
   public StopAnalyzer(String[] stopWords) {
     this.stopWords = StopFilter.makeStopSet(stopWords);
     useDefaultStopPositionIncrement = true;
@@ -108,7 +137,7 @@ public StopAnalyzer(String[] stopWords) {
    * @param stopWords Array of stop words
    * @param enablePositionIncrements See {@link
    * StopFilter#setEnablePositionIncrements} 
-   * @deprecated Use {@link #StopAnalyzer(Set, boolean)} instead*/
+   * @deprecated Use {@link #StopAnalyzer(Version, Set)} instead*/
   public StopAnalyzer(String[] stopWords, boolean enablePositionIncrements) {
     this.stopWords = StopFilter.makeStopSet(stopWords);
     this.enablePositionIncrements = enablePositionIncrements;
@@ -117,7 +146,7 @@ public StopAnalyzer(String[] stopWords, boolean enablePositionIncrements) {
   
   /** Builds an analyzer with the stop words from the given file.
    * @see WordlistLoader#getWordSet(File)
-   * @deprecated Use {@link #StopAnalyzer(File, boolean)} instead */
+   * @deprecated Use {@link #StopAnalyzer(Version, File)} instead */
   public StopAnalyzer(File stopwordsFile) throws IOException {
     stopWords = WordlistLoader.getWordSet(stopwordsFile);
     useDefaultStopPositionIncrement = true;
@@ -128,16 +157,27 @@ public StopAnalyzer(File stopwordsFile) throws IOException {
    * @see WordlistLoader#getWordSet(File)
    * @param stopwordsFile File to load stop words from
    * @param enablePositionIncrements See {@link
-   * StopFilter#setEnablePositionIncrements} */
+   * StopFilter#setEnablePositionIncrements}
+   * @deprecated Use {@link #StopAnalyzer(Version, File)} instead */
   public StopAnalyzer(File stopwordsFile, boolean enablePositionIncrements) throws IOException {
     stopWords = WordlistLoader.getWordSet(stopwordsFile);
     this.enablePositionIncrements = enablePositionIncrements;
     useDefaultStopPositionIncrement = false;
   }
 
+  /** Builds an analyzer with the stop words from the given file.
+   * @see WordlistLoader#getWordSet(File)
+   * @param matchVersion See <a href="#version">above</a>
+   * @param stopwordsFile File to load stop words from */
+  public StopAnalyzer(Version matchVersion, File stopwordsFile) throws IOException {
+    stopWords = WordlistLoader.getWordSet(stopwordsFile);
+    this.enablePositionIncrements = StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion);
+    useDefaultStopPositionIncrement = false;
+  }
+
   /** Builds an analyzer with the stop words from the given reader.
    * @see WordlistLoader#getWordSet(Reader)
-   * @deprecated Use {@link #StopAnalyzer(Reader, boolean)} instead
+   * @deprecated Use {@link #StopAnalyzer(Version, Reader)} instead
    */
   public StopAnalyzer(Reader stopwords) throws IOException {
     stopWords = WordlistLoader.getWordSet(stopwords);
@@ -149,13 +189,24 @@ public StopAnalyzer(Reader stopwords) throws IOException {
    * @see WordlistLoader#getWordSet(Reader)
    * @param stopwords Reader to load stop words from
    * @param enablePositionIncrements See {@link
-   * StopFilter#setEnablePositionIncrements} */
+   * StopFilter#setEnablePositionIncrements}
+   * @deprecated Use {@link #StopAnalyzer(Version, Reader)} instead */
   public StopAnalyzer(Reader stopwords, boolean enablePositionIncrements) throws IOException {
     stopWords = WordlistLoader.getWordSet(stopwords);
     this.enablePositionIncrements = enablePositionIncrements;
     useDefaultStopPositionIncrement = false;
   }
 
+  /** Builds an analyzer with the stop words from the given reader.
+   * @see WordlistLoader#getWordSet(Reader)
+   * @param matchVersion See <a href="#version">above</a>
+   * @param stopwords Reader to load stop words from */
+  public StopAnalyzer(Version matchVersion, Reader stopwords) throws IOException {
+    stopWords = WordlistLoader.getWordSet(stopwords);
+    this.enablePositionIncrements = StopFilter.getEnablePositionIncrementsVersionDefault(matchVersion);
+    useDefaultStopPositionIncrement = false;
+  }
+
   /** Filters LowerCaseTokenizer with StopFilter. */
   public TokenStream tokenStream(String fieldName, Reader reader) {
     if (useDefaultStopPositionIncrement) {
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopFilter.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopFilter.java
index 5e98f2af..dd689fa9 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopFilter.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/StopFilter.java
@@ -25,6 +25,7 @@
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 import org.apache.lucene.queryParser.QueryParser; // for javadoc
+import org.apache.lucene.util.Version;
 
 /**
  * Removes stop words from a token stream.
@@ -242,6 +243,21 @@ public static boolean getEnablePositionIncrementsDefault() {
     return ENABLE_POSITION_INCREMENTS_DEFAULT;
   }
 
+  /**
+   * Returns version-dependent default for
+   * enablePositionIncrements.  Analyzers that embed
+   * StopFilter use this method when creating the
+   * StopFilter.  Prior to 2.9, this returns false.  On 2.9
+   * or later, it returns true.
+   */
+  public static boolean getEnablePositionIncrementsVersionDefault(Version matchVersion) {
+    if (matchVersion.onOrAfter(Version.LUCENE_29)) {
+      return true;
+    } else {
+      return false;
+    }
+  }
+
   /**
    * Set the default position increments behavior of every StopFilter created from now on.
    * <p>
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index 51c9d8a9..e57a6d0e 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -35,7 +35,7 @@
  * compatibility when creating StandardAnalyzer:
  * <ul>
  *   <li> As of 2.9, StopFilter preserves position
- *        increments by default
+ *        increments
  *   <li> As of 2.4, Tokens incorrectly identified as acronyms
  *        are corrected (see <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a>
  * </ul>
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index c0e3bdca..8da51c7b 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -27,6 +27,7 @@
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.Version;
 
 /** A grammar-based tokenizer constructed with JFlex
  *
@@ -43,6 +44,14 @@
  * <p>Many applications have specific tokenizer needs.  If this tokenizer does
  * not suit your application, please consider copying this source code
  * directory to your project and maintaining your own grammar-based tokenizer.
+ *
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating StandardAnalyzer:
+ * <ul>
+ *   <li> As of 2.4, Tokens incorrectly identified as acronyms
+ *        are corrected (see <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a>
+ * </ul>
  */
 
 public class StandardTokenizer extends Tokenizer {
@@ -107,9 +116,12 @@ public int getMaxTokenLength() {
   /**
    * Creates a new instance of the {@link StandardTokenizer}. Attaches the
    * <code>input</code> to a newly created JFlex scanner.
+   *
+   * @deprecated Use {@link #StandardTokenizer(Version,
+   * Reader)} instead
    */
   public StandardTokenizer(Reader input) {
-    this(input, false);
+    this(Version.LUCENE_24, input);
   }
 
   /**
@@ -120,6 +132,8 @@ public StandardTokenizer(Reader input) {
    * @param replaceInvalidAcronym Set to true to replace mischaracterized acronyms with HOST.
    *
    * See http://issues.apache.org/jira/browse/LUCENE-1068
+   *
+   * @deprecated Use {@link #StandardTokenizer(Version, Reader)} instead
    */
   public StandardTokenizer(Reader input, boolean replaceInvalidAcronym) {
     super();
@@ -127,8 +141,24 @@ public StandardTokenizer(Reader input, boolean replaceInvalidAcronym) {
     init(input, replaceInvalidAcronym);
   }
 
+  /**
+   * Creates a new instance of the {@link org.apache.lucene.analysis.standard.StandardTokenizer}.  Attaches
+   * the <code>input</code> to the newly created JFlex scanner.
+   *
+   * @param input The input reader
+   *
+   * See http://issues.apache.org/jira/browse/LUCENE-1068
+   */
+  public StandardTokenizer(Version matchVersion, Reader input) {
+    super();
+    this.scanner = new StandardTokenizerImpl(input);
+    init(input, matchVersion);
+  }
+
   /**
    * Creates a new StandardTokenizer with a given {@link AttributeSource}. 
+   *
+   * @deprecated Use {@link #StandardTokenizer(Version, AttributeSource, Reader)} instead
    */
   public StandardTokenizer(AttributeSource source, Reader input, boolean replaceInvalidAcronym) {
     super(source);
@@ -136,8 +166,19 @@ public StandardTokenizer(AttributeSource source, Reader input, boolean replaceIn
     init(input, replaceInvalidAcronym);
   }
 
+  /**
+   * Creates a new StandardTokenizer with a given {@link AttributeSource}. 
+   */
+  public StandardTokenizer(Version matchVersion, AttributeSource source, Reader input) {
+    super(source);
+    this.scanner = new StandardTokenizerImpl(input);
+    init(input, matchVersion);
+  }
+
   /**
    * Creates a new StandardTokenizer with a given {@link org.apache.lucene.util.AttributeSource.AttributeFactory} 
+   *
+   * @deprecated Use {@link #StandardTokenizer(Version, org.apache.lucene.util.AttributeSource.AttributeFactory, Reader)} instead
    */
   public StandardTokenizer(AttributeFactory factory, Reader input, boolean replaceInvalidAcronym) {
     super(factory);
@@ -145,6 +186,15 @@ public StandardTokenizer(AttributeFactory factory, Reader input, boolean replace
     init(input, replaceInvalidAcronym);
   }
 
+  /**
+   * Creates a new StandardTokenizer with a given {@link org.apache.lucene.util.AttributeSource.AttributeFactory} 
+   */
+  public StandardTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {
+    super(factory);
+    this.scanner = new StandardTokenizerImpl(input);
+    init(input, matchVersion);
+  }
+
   private void init(Reader input, boolean replaceInvalidAcronym) {
     this.replaceInvalidAcronym = replaceInvalidAcronym;
     this.input = input;    
@@ -154,6 +204,14 @@ private void init(Reader input, boolean replaceInvalidAcronym) {
     typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
   }
   
+  private void init(Reader input, Version matchVersion) {
+    if (matchVersion.onOrAfter(Version.LUCENE_24)) {
+      init(input, true);
+    } else {
+      init(input, false);
+    }
+  }
+  
   // this tokenizer generates three attributes:
   // offset, positionIncrement and type
   private TermAttribute termAtt;
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/MultiFieldQueryParser.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/MultiFieldQueryParser.java
index a73dcfc8..56e682ca 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/MultiFieldQueryParser.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/MultiFieldQueryParser.java
@@ -27,6 +27,7 @@
 import org.apache.lucene.search.MultiPhraseQuery;
 import org.apache.lucene.search.PhraseQuery;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.util.Version;
 
 /**
  * A QueryParser which constructs queries to search multiple fields.
@@ -64,9 +65,43 @@
    *
    * <p>In other words, all the query's terms must appear, but it doesn't matter in
    * what fields they appear.</p>
+   *
+   * @deprecated Please use {@link #MultiFieldQueryParser(Version, String[], Analyzer, Map)} instead
    */
   public MultiFieldQueryParser(String[] fields, Analyzer analyzer, Map boosts) {
-    this(fields,analyzer);
+    this(Version.LUCENE_24, fields, analyzer);
+    this.boosts = boosts;
+  }
+  
+  /**
+   * Creates a MultiFieldQueryParser. 
+   * Allows passing of a map with term to Boost, and the boost to apply to each term.
+   *
+   * <p>It will, when parse(String query)
+   * is called, construct a query like this (assuming the query consists of
+   * two terms and you specify the two fields <code>title</code> and <code>body</code>):</p>
+   * 
+   * <code>
+   * (title:term1 body:term1) (title:term2 body:term2)
+   * </code>
+   *
+   * <p>When setDefaultOperator(AND_OPERATOR) is set, the result will be:</p>
+   *  
+   * <code>
+   * +(title:term1 body:term1) +(title:term2 body:term2)
+   * </code>
+   * 
+   * <p>When you pass a boost (title=>5 body=>10) you can get </p>
+   * 
+   * <code>
+   * +(title:term1^5.0 body:term1^10.0) +(title:term2^5.0 body:term2^10.0)
+   * </code>
+   *
+   * <p>In other words, all the query's terms must appear, but it doesn't matter in
+   * what fields they appear.</p>
+   */
+  public MultiFieldQueryParser(Version matchVersion, String[] fields, Analyzer analyzer, Map boosts) {
+    this(matchVersion, fields, analyzer);
     this.boosts = boosts;
   }
   
@@ -89,9 +124,35 @@ public MultiFieldQueryParser(String[] fields, Analyzer analyzer, Map boosts) {
    * 
    * <p>In other words, all the query's terms must appear, but it doesn't matter in
    * what fields they appear.</p>
+   *
+   * @deprecated Please use {@link #MultiFieldQueryParser(Version, String[], Analyzer)} instead
    */
   public MultiFieldQueryParser(String[] fields, Analyzer analyzer) {
-    super(null, analyzer);
+    this(Version.LUCENE_24, fields, analyzer);
+  }
+  
+  /**
+   * Creates a MultiFieldQueryParser.
+   *
+   * <p>It will, when parse(String query)
+   * is called, construct a query like this (assuming the query consists of
+   * two terms and you specify the two fields <code>title</code> and <code>body</code>):</p>
+   * 
+   * <code>
+   * (title:term1 body:term1) (title:term2 body:term2)
+   * </code>
+   *
+   * <p>When setDefaultOperator(AND_OPERATOR) is set, the result will be:</p>
+   *  
+   * <code>
+   * +(title:term1 body:term1) +(title:term2 body:term2)
+   * </code>
+   * 
+   * <p>In other words, all the query's terms must appear, but it doesn't matter in
+   * what fields they appear.</p>
+   */
+  public MultiFieldQueryParser(Version matchVersion, String[] fields, Analyzer analyzer) {
+    super(matchVersion, null, analyzer);
     this.fields = fields;
   }
   
@@ -202,16 +263,40 @@ protected Query getRangeQuery(String field, String part1, String part2, boolean
    * @throws ParseException if query parsing fails
    * @throws IllegalArgumentException if the length of the queries array differs
    *  from the length of the fields array
+   * @deprecated Use {@link #parse(Version,String[],String[],Analyzer)} instead
    */
   public static Query parse(String[] queries, String[] fields,
       Analyzer analyzer) throws ParseException
+  {
+    return parse(Version.LUCENE_24, queries, fields, analyzer);
+  }
+
+  /**
+   * Parses a query which searches on the fields specified.
+   * <p>
+   * If x fields are specified, this effectively constructs:
+   * <pre>
+   * <code>
+   * (field1:query1) (field2:query2) (field3:query3)...(fieldx:queryx)
+   * </code>
+   * </pre>
+   * @param matchVersion Lucene version to match; this is passed through to QueryParser.
+   * @param queries Queries strings to parse
+   * @param fields Fields to search on
+   * @param analyzer Analyzer to use
+   * @throws ParseException if query parsing fails
+   * @throws IllegalArgumentException if the length of the queries array differs
+   *  from the length of the fields array
+   */
+  public static Query parse(Version matchVersion, String[] queries, String[] fields,
+      Analyzer analyzer) throws ParseException
   {
     if (queries.length != fields.length)
       throw new IllegalArgumentException("queries.length != fields.length");
     BooleanQuery bQuery = new BooleanQuery();
     for (int i = 0; i < fields.length; i++)
     {
-      QueryParser qp = new QueryParser(fields[i], analyzer);
+      QueryParser qp = new QueryParser(matchVersion, fields[i], analyzer);
       Query q = qp.parse(queries[i]);
       if (q!=null && // q never null, just being defensive
           (!(q instanceof BooleanQuery) || ((BooleanQuery)q).getClauses().length>0)) {
@@ -250,14 +335,51 @@ public static Query parse(String[] queries, String[] fields,
    * @throws ParseException if query parsing fails
    * @throws IllegalArgumentException if the length of the fields array differs
    *  from the length of the flags array
+   * @deprecated Use {@link #parse(Version, String, String[], BooleanClause.Occur[], Analyzer)} instead
    */
   public static Query parse(String query, String[] fields,
       BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
+    return parse(Version.LUCENE_24, query, fields, flags, analyzer);
+  }
+
+  /**
+   * Parses a query, searching on the fields specified.
+   * Use this if you need to specify certain fields as required,
+   * and others as prohibited.
+   * <p><pre>
+   * Usage:
+   * <code>
+   * String[] fields = {"filename", "contents", "description"};
+   * BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
+   *                BooleanClause.Occur.MUST,
+   *                BooleanClause.Occur.MUST_NOT};
+   * MultiFieldQueryParser.parse("query", fields, flags, analyzer);
+   * </code>
+   * </pre>
+   *<p>
+   * The code above would construct a query:
+   * <pre>
+   * <code>
+   * (filename:query) +(contents:query) -(description:query)
+   * </code>
+   * </pre>
+   *
+   * @param matchVersion Lucene version to match; this is passed through to QueryParser.
+   * @param query Query string to parse
+   * @param fields Fields to search on
+   * @param flags Flags describing the fields
+   * @param analyzer Analyzer to use
+   * @throws ParseException if query parsing fails
+   * @throws IllegalArgumentException if the length of the fields array differs
+   *  from the length of the flags array
+   */
+  public static Query parse(Version matchVersion, String query, String[] fields,
+      BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
     if (fields.length != flags.length)
       throw new IllegalArgumentException("fields.length != flags.length");
     BooleanQuery bQuery = new BooleanQuery();
     for (int i = 0; i < fields.length; i++) {
-      QueryParser qp = new QueryParser(fields[i], analyzer);
+      QueryParser qp = new QueryParser(matchVersion, fields[i], analyzer);
       Query q = qp.parse(query);
       if (q!=null && // q never null, just being defensive 
           (!(q instanceof BooleanQuery) || ((BooleanQuery)q).getClauses().length>0)) {
@@ -297,16 +419,55 @@ public static Query parse(String query, String[] fields,
    * @throws ParseException if query parsing fails
    * @throws IllegalArgumentException if the length of the queries, fields,
    *  and flags array differ
+   * @deprecated Used {@link #parse(Version, String[], String[], BooleanClause.Occur[], Analyzer)} instead
    */
   public static Query parse(String[] queries, String[] fields, BooleanClause.Occur[] flags,
       Analyzer analyzer) throws ParseException
+  {
+    return parse(Version.LUCENE_24, queries, fields, flags, analyzer);
+  }
+
+  /**
+   * Parses a query, searching on the fields specified.
+   * Use this if you need to specify certain fields as required,
+   * and others as prohibited.
+   * <p><pre>
+   * Usage:
+   * <code>
+   * String[] query = {"query1", "query2", "query3"};
+   * String[] fields = {"filename", "contents", "description"};
+   * BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
+   *                BooleanClause.Occur.MUST,
+   *                BooleanClause.Occur.MUST_NOT};
+   * MultiFieldQueryParser.parse(query, fields, flags, analyzer);
+   * </code>
+   * </pre>
+   *<p>
+   * The code above would construct a query:
+   * <pre>
+   * <code>
+   * (filename:query1) +(contents:query2) -(description:query3)
+   * </code>
+   * </pre>
+   *
+   * @param matchVersion Lucene version to match; this is passed through to QueryParser.
+   * @param queries Queries string to parse
+   * @param fields Fields to search on
+   * @param flags Flags describing the fields
+   * @param analyzer Analyzer to use
+   * @throws ParseException if query parsing fails
+   * @throws IllegalArgumentException if the length of the queries, fields,
+   *  and flags array differ
+   */
+  public static Query parse(Version matchVersion, String[] queries, String[] fields, BooleanClause.Occur[] flags,
+      Analyzer analyzer) throws ParseException
   {
     if (!(queries.length == fields.length && queries.length == flags.length))
       throw new IllegalArgumentException("queries, fields, and flags array have have different length");
     BooleanQuery bQuery = new BooleanQuery();
     for (int i = 0; i < fields.length; i++)
     {
-      QueryParser qp = new QueryParser(fields[i], analyzer);
+      QueryParser qp = new QueryParser(matchVersion, fields[i], analyzer);
       Query q = qp.parse(queries[i]);
       if (q!=null && // q never null, just being defensive
           (!(q instanceof BooleanQuery) || ((BooleanQuery)q).getClauses().length>0)) {
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParser.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParser.java
index 369e59c8..149f7399 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParser.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParser.java
@@ -35,6 +35,7 @@
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.util.Parameter;
+import org.apache.lucene.util.Version;
 
 /**
  * This class is generated by JavaCC.  The most important method is
@@ -101,6 +102,14 @@
  * <p><b>NOTE</b>: there is a new QueryParser in contrib, which matches
  * the same syntax as this class, but is more modular,
  * enabling substantial customization to how a query is created.
+ *
+ * <a name="version"/>
+ * <p><b>NOTE</b>: You must specify the required {@link Version}
+ * compatibility when creating QueryParser:
+ * <ul>
+ *    <li> As of 2.9, {@link #setEnablePositionIncrements} is true by
+ *         default.
+ * </ul>
  */
 public class QueryParser implements QueryParserConstants {
 
@@ -125,7 +134,7 @@
   boolean lowercaseExpandedTerms = true;
   MultiTermQuery.RewriteMethod multiTermRewriteMethod = MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT;
   boolean allowLeadingWildcard = false;
-  boolean enablePositionIncrements = false;
+  boolean enablePositionIncrements = true;
 
   Analyzer analyzer;
   String field;
@@ -158,11 +167,26 @@ private Operator(String name) {
   /** Constructs a query parser.
    *  @param f  the default field for query terms.
    *  @param a   used to find terms in the query text.
+   *  @deprecated Use {@link #QueryParser(Version, String, Analyzer)} instead
    */
   public QueryParser(String f, Analyzer a) {
+    this(Version.LUCENE_24, f, a);
+  }
+
+  /** Constructs a query parser.
+   *  @param matchVersion  Lucene version to match.  See <a href="#version">above</a>)
+   *  @param f  the default field for query terms.
+   *  @param a   used to find terms in the query text.
+   */
+  public QueryParser(Version matchVersion, String f, Analyzer a) {
     this(new FastCharStream(new StringReader("")));
     analyzer = a;
     field = f;
+    if (matchVersion.onOrAfter(Version.LUCENE_29)) {
+      enablePositionIncrements = true;
+    } else {
+      enablePositionIncrements = false;
+    }
   }
 
   /** Parses a query string, returning a {@link org.apache.lucene.search.Query}.
@@ -759,7 +783,7 @@ protected Query getRangeQuery(String field,
       DateTools.Resolution resolution = getDateResolution(field);
       if (resolution == null) {
         // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibilty with
+        // use deprecated DateField to maintain compatibility with
         // pre-1.9 Lucene versions.
         part1 = DateField.dateToString(d1);
         part2 = DateField.dateToString(d2);
@@ -1155,7 +1179,7 @@ public static void main(String[] args) throws Exception {
       System.out.println("Usage: java org.apache.lucene.queryParser.QueryParser <input>");
       System.exit(0);
     }
-    QueryParser qp = new QueryParser("field",
+    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, "field",
                            new org.apache.lucene.analysis.SimpleAnalyzer());
     Query q = qp.parse(args[0]);
     System.out.println(q.toString("field"));
@@ -1591,6 +1615,12 @@ private boolean jj_2_1(int xla) {
     finally { jj_save(0, xla); }
   }
 
+  private boolean jj_3R_2() {
+    if (jj_scan_token(TERM)) return true;
+    if (jj_scan_token(COLON)) return true;
+    return false;
+  }
+
   private boolean jj_3_1() {
     Token xsp;
     xsp = jj_scanpos;
@@ -1607,12 +1637,6 @@ private boolean jj_3R_3() {
     return false;
   }
 
-  private boolean jj_3R_2() {
-    if (jj_scan_token(TERM)) return true;
-    if (jj_scan_token(COLON)) return true;
-    return false;
-  }
-
   /** Generated Token Manager. */
   public QueryParserTokenManager token_source;
   /** Current token. */
@@ -1641,7 +1665,7 @@ private static void jj_la1_init_1() {
   private int jj_gc = 0;
 
   /** Constructor with user supplied CharStream. */
-  public QueryParser(CharStream stream) {
+  protected QueryParser(CharStream stream) {
     token_source = new QueryParserTokenManager(stream);
     token = new Token();
     jj_ntk = -1;
@@ -1661,7 +1685,7 @@ public void ReInit(CharStream stream) {
   }
 
   /** Constructor with generated Token Manager. */
-  public QueryParser(QueryParserTokenManager tm) {
+  protected QueryParser(QueryParserTokenManager tm) {
     token_source = tm;
     token = new Token();
     jj_ntk = -1;
diff --git a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
index 2dc793f1..18944a2e 100644
--- a/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
+++ b/lucene/java/branches/lucene_2_9/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.util.Parameter;
+import org.apache.lucene.util.Version;
 
 /** Token Manager. */
 public class QueryParserTokenManager implements QueryParserConstants
diff --git a/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java b/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java
index 3ae40923..33a40abd 100644
--- a/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java
+++ b/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java
@@ -5,6 +5,7 @@
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.Version;
 
 import java.io.StringReader;
 
@@ -108,15 +109,24 @@ public void testLucene1140() throws Exception {
   }
 
   public void testDomainNames() throws Exception {
-    // Don't reuse a because we alter its state (setReplaceInvalidAcronym)
-    StandardAnalyzer a2 = new StandardAnalyzer();
+    // Don't reuse a because we alter its state
+    // (setReplaceInvalidAcronym)
+
+    // Current lucene should not show the bug
+    StandardAnalyzer a2 = new StandardAnalyzer(Version.LUCENE_CURRENT);
     // domain names
     assertAnalyzesTo(a2, "www.nutch.org", new String[]{"www.nutch.org"});
     //Notice the trailing .  See https://issues.apache.org/jira/browse/LUCENE-1068.
     // the following should be recognized as HOST:
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
-    a2.setReplaceInvalidAcronym(false);
+
+    // 2.3 should show the bug
+    a2 = new StandardAnalyzer(Version.LUCENE_23);
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "wwwnutchorg" }, new String[] { "<ACRONYM>" });
+
+    // 2.4 should not show the bug
+    a2 = new StandardAnalyzer(Version.LUCENE_24);
+    assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
   }
 
   public void testEMailAddresses() throws Exception {
diff --git a/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/queryParser/TestQueryParser.java b/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/queryParser/TestQueryParser.java
index 1bd4f23c..48fa31ad 100644
--- a/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/queryParser/TestQueryParser.java
+++ b/lucene/java/branches/lucene_2_9/src/test/org/apache/lucene/queryParser/TestQueryParser.java
@@ -47,6 +47,7 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MultiTermQuery;
 import org.apache.lucene.search.FuzzyQuery;
@@ -60,7 +61,10 @@
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.util.LocalizedTestCase;
+import org.apache.lucene.util.Version;
 
 /**
  * Tests QueryParser.
@@ -1014,4 +1018,49 @@ public void tearDown() throws Exception {
     BooleanQuery.setMaxClauseCount(originalMaxClauses);
   }
 
+  // LUCENE-2002: make sure defaults for StandardAnalyzer's
+  // enableStopPositionIncr & QueryParser's enablePosIncr
+  // "match"
+  public void testPositionIncrements() throws Exception {
+    Directory dir = new MockRAMDirectory();
+    Analyzer a = new StandardAnalyzer(Version.LUCENE_CURRENT);
+    IndexWriter w = new IndexWriter(dir, a, IndexWriter.MaxFieldLength.UNLIMITED);
+    Document doc = new Document();
+    doc.add(new Field("f", "the wizard of ozzy", Field.Store.NO, Field.Index.ANALYZED));
+    w.addDocument(doc);
+    IndexReader r = w.getReader();
+    w.close();
+    IndexSearcher s = new IndexSearcher(r);
+    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, "f", a);
+    Query q = qp.parse("\"wizard of ozzy\"");
+    assertEquals(1, s.search(q, 1).totalHits);
+    r.close();
+    dir.close();
+  }
+
+  // LUCENE-2002: when we run javacc to regen QueryParser,
+  // we also run a replaceregexp step to fix 2 of the public
+  // ctors (change them to protected):
+  //
+  //   protected QueryParser(CharStream stream)
+  //
+  //   protected QueryParser(QueryParserTokenManager tm)
+  //
+  // This test is here as a safety, in case that ant step
+  // doesn't work for some reason.
+  public void testProtectedCtors() throws Exception {
+    try {
+      QueryParser.class.getConstructor(new Class[] {CharStream.class});
+      fail("please switch public QueryParser(CharStream) to be protected");
+    } catch (NoSuchMethodException nsme) {
+      // expected
+    }
+    try {
+      QueryParser.class.getConstructor(new Class[] {QueryParserTokenManager.class});
+      fail("please switch public QueryParser(QueryParserTokenManager) to be protected");
+    } catch (NoSuchMethodException nsme) {
+      // expected
+    }
+  }
+
 }
